{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdbaf99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import f1_score,balanced_accuracy_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler,ADASYN\n",
    "from imblearn.pipeline import make_pipeline as pipe_imblearn\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "from oversampling_aco import OVRS_ACO\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aa0c7f",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e47947fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/NR_AB.csv\").drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954b02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['label','drug_no','protein_no'],axis=1)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9dd888",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cad6bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4cc84b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1c511c",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a04c24e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 1\n",
    "n_ovrs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b85eba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(random_state = random_state)\n",
    "oversampler = ADASYN(sampling_strategy={target:n_ovrs},random_state=random_state, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8f63491",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_pheromone_test = [np.round(i,1) for i in np.arange(0.1,1,0.1)] + [1]\n",
    "rho_test = [np.round(i,1) for i in np.arange(0.1,1,0.1)] + [1]\n",
    "num_ant_test = [20,30,40,50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4029bfef",
   "metadata": {},
   "source": [
    "## init_pheromone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed739bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test case =  0.1\n",
      "f1 =  0.4\n",
      "gm =  0.5482097623670511\n",
      "bas =  0.6459082488830772\n",
      "\n",
      "test case =  0.2\n",
      "f1 =  0.4\n",
      "gm =  0.5482097623670511\n",
      "bas =  0.6459082488830772\n",
      "\n",
      "test case =  0.3\n",
      "f1 =  0.4\n",
      "gm =  0.5482097623670511\n",
      "bas =  0.6459082488830772\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m ovrs_aco \u001b[38;5;241m=\u001b[39m OVRS_ACO(init_pheromone\u001b[38;5;241m=\u001b[39mtest_case,rho\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,num_ant\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,max_idem\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,kfold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m      4\u001b[0m ovrs_aco\u001b[38;5;241m.\u001b[39mset_model(X_train, y_train,\n\u001b[0;32m      5\u001b[0m                    ovrs_target\u001b[38;5;241m=\u001b[39mtarget, n_ovrs_target\u001b[38;5;241m=\u001b[39mn_ovrs,\n\u001b[0;32m      6\u001b[0m                    model \u001b[38;5;241m=\u001b[39m model, oversampler \u001b[38;5;241m=\u001b[39m oversampler)\n\u001b[1;32m----> 8\u001b[0m new_X_train,new_y_train,fitness,fitness_history \u001b[38;5;241m=\u001b[39m ovrs_aco\u001b[38;5;241m.\u001b[39mconstruct_solution()\n\u001b[0;32m     10\u001b[0m model_ovrs_aco \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m     12\u001b[0m model_ovrs_aco\u001b[38;5;241m.\u001b[39mfit(new_X_train,new_y_train)\n",
      "File \u001b[1;32m~\\Documents\\kuliah\\tesis lija\\DTI-Prediction-Imbalanced-Data\\oversampling_aco.py:149\u001b[0m, in \u001b[0;36mOVRS_ACO.construct_solution\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    146\u001b[0m kf_new_y_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([kf_y_train\u001b[38;5;241m.\u001b[39mcopy(),chosen_y_smote])\n\u001b[0;32m    148\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m make_pipeline(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m--> 149\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mfit(kf_new_X_train,kf_new_y_train)\n\u001b[0;32m    150\u001b[0m fitness \u001b[38;5;241m=\u001b[39m f1_score(kf_y_test,pipeline\u001b[38;5;241m.\u001b[39mpredict(kf_X_test),pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    152\u001b[0m fold_results\u001b[38;5;241m.\u001b[39mappend(fitness)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:538\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    537\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stages(\n\u001b[0;32m    539\u001b[0m     X,\n\u001b[0;32m    540\u001b[0m     y,\n\u001b[0;32m    541\u001b[0m     raw_predictions,\n\u001b[0;32m    542\u001b[0m     sample_weight,\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng,\n\u001b[0;32m    544\u001b[0m     X_val,\n\u001b[0;32m    545\u001b[0m     y_val,\n\u001b[0;32m    546\u001b[0m     sample_weight_val,\n\u001b[0;32m    547\u001b[0m     begin_at_stage,\n\u001b[0;32m    548\u001b[0m     monitor,\n\u001b[0;32m    549\u001b[0m )\n\u001b[0;32m    551\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:615\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    608\u001b[0m     old_oob_score \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    609\u001b[0m         y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    610\u001b[0m         raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    611\u001b[0m         sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    612\u001b[0m     )\n\u001b[0;32m    614\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stage(\n\u001b[0;32m    616\u001b[0m     i,\n\u001b[0;32m    617\u001b[0m     X,\n\u001b[0;32m    618\u001b[0m     y,\n\u001b[0;32m    619\u001b[0m     raw_predictions,\n\u001b[0;32m    620\u001b[0m     sample_weight,\n\u001b[0;32m    621\u001b[0m     sample_mask,\n\u001b[0;32m    622\u001b[0m     random_state,\n\u001b[0;32m    623\u001b[0m     X_csc,\n\u001b[0;32m    624\u001b[0m     X_csr,\n\u001b[0;32m    625\u001b[0m )\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:257\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    254\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    256\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 257\u001b[0m tree\u001b[38;5;241m.\u001b[39mfit(X, residual, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    260\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    261\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[0;32m    262\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    270\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m   1248\u001b[0m         X,\n\u001b[0;32m   1249\u001b[0m         y,\n\u001b[0;32m   1250\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1251\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_results = []\n",
    "for test_case in init_pheromone_test:\n",
    "    ovrs_aco = OVRS_ACO(init_pheromone=test_case,rho=0.8,num_ant=20,max_idem=10,kfold=5,random_state=random_state)\n",
    "    ovrs_aco.set_model(X_train, y_train,\n",
    "                       ovrs_target=target, n_ovrs_target=n_ovrs,\n",
    "                       model = model, oversampler = oversampler)\n",
    "\n",
    "    new_X_train,new_y_train,fitness,fitness_history = ovrs_aco.construct_solution()\n",
    "    \n",
    "    model_ovrs_aco = model\n",
    "    \n",
    "    model_ovrs_aco.fit(new_X_train,new_y_train)\n",
    "    \n",
    "    f1 = f1_score(y_test, model_ovrs_aco.predict(X_test))\n",
    "    test_results.append(f1)\n",
    "    \n",
    "    print(\"test case = \",test_case)\n",
    "    print(\"f1 = \", f1)\n",
    "    print(\"gm = \", geometric_mean_score(y_test, model_ovrs_aco.predict(X_test)))\n",
    "    print(\"bas = \", balanced_accuracy_score(y_test, model_ovrs_aco.predict(X_test)))\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b667bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_case = np.argmax(test_results)\n",
    "best_init_pheromone = init_pheromone_test[best_test_case] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75053b7",
   "metadata": {},
   "source": [
    "## rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c3874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []\n",
    "for test_case in rho_test:\n",
    "    ovrs_aco = OVRS_ACO(init_pheromone=best_init_pheromone,rho=test_case,num_ant=20,max_iter=100,max_idem=10,kfold=5,random_state=random_state)\n",
    "    ovrs_aco.set_model(X_train, y_train,\n",
    "                       ovrs_target=target, n_ovrs_target=n_ovrs,\n",
    "                       model = model, oversampler = oversampler)\n",
    "\n",
    "    new_X_train,new_y_train,fitness,fitness_history = ovrs_aco.construct_solution()\n",
    "    \n",
    "    model_ovrs_aco = model\n",
    "    \n",
    "    model_ovrs_aco.fit(new_X_train,new_y_train)\n",
    "    \n",
    "    f1 = f1_score(y_test, model_ovrs_aco.predict(X_test))\n",
    "    test_results.append(f1)\n",
    "    \n",
    "    print(\"test case = \",test_case)\n",
    "    print(\"f1 = \", f1)\n",
    "    print(\"gm = \", geometric_mean_score(y_test, model_ovrs_aco.predict(X_test)))\n",
    "    print(\"bas = \", balanced_accuracy_score(y_test, model_ovrs_aco.predict(X_test)))\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40f393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_case = np.argmax(test_results)\n",
    "best_rho = rho_test[best_test_case] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c407e86",
   "metadata": {},
   "source": [
    "## num_ant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c321e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []\n",
    "for test_case in num_ant_test:\n",
    "    ovrs_aco = OVRS_ACO(init_pheromone=best_init_pheromone,rho=best_rho,num_ant=test_case,max_iter=100,max_idem=10,kfold=5,random_state=random_state)\n",
    "    ovrs_aco.set_model(X_train, y_train,\n",
    "                       ovrs_target=target, n_ovrs_target=n_ovrs,\n",
    "                       model = model, oversampler = oversampler)\n",
    "\n",
    "    new_X_train,new_y_train,fitness,fitness_history = ovrs_aco.construct_solution()\n",
    "    \n",
    "    model_ovrs_aco = model\n",
    "    \n",
    "    model_ovrs_aco.fit(new_X_train,new_y_train)\n",
    "    \n",
    "    f1 = f1_score(y_test, model_ovrs_aco.predict(X_test))\n",
    "    test_results.append(f1)\n",
    "    \n",
    "    print(\"test case = \",test_case)\n",
    "    print(\"f1 = \", f1)\n",
    "    print(\"gm = \", geometric_mean_score(y_test, model_ovrs_aco.predict(X_test)))\n",
    "    print(\"bas = \", balanced_accuracy_score(y_test, model_ovrs_aco.predict(X_test)))\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1879278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_case = np.argmax(test_results)\n",
    "best_num_ant = num_ant_test[best_test_case] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2294d6d",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best init pheromone = \",best_init_pheromone)\n",
    "print(\"best rho = \",best_rho)\n",
    "print(\"best num_ant = \",best_num_ant)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
